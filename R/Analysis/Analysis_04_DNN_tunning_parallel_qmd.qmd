---
title: "Hematological Clock 016" 
subtitle: "(Sex :`r params$sex`, Strain:`r params$strain`) "

author: "Jorge Martinez-Romero"
date: "2023-07-28"
format: html 
params:
  sex: "All" # "F", "M", "All". 
  strain: "All" # "B6", "HET3", "DO", "All"
toc: true   
self-contained: true  
---


## DNN TUNNING HYPER-PARAMETERS

GOAL: Find a reasonable optimal DNN configuration (Train 2000 DNNs)
STRATEGY: Find an efficient architecture by building models with different depth, going from 4 layers to 6 layers. Include different number of neurons going from 2x- to 32x- (Inputs = number of predictors + levels in the model). Include different penalization parameters L1 and L2. Include chronological information as a delta-predictor. Consider both flat or incremental neuron number approaches. Use approx 70 % dataset in a 10F-CV process to train and test the models. 
Select the final model with minimum MAE and higher correlation coefficient between predicted age and chrono age in the 10FCV performed in the training dataset only.


```{r ,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Biowulf: patho <-"/data/martinezromerj2/0014_Blood_Clock_2023/"
# Local
patho<-"W:/0016_Hematological_clock_2023_Git/"
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, messages=FALSE, comment = NA, root.dir = patho, fig.pos = 'H')
options(max.print=2000,future.globals.maxSize = 4000 * 1024^5)

```

```{r libraries, echo=FALSE, include=FALSE,message=FALSE}
library("tidyverse")
library("groupdata2")
library("h2o")
library("kableExtra")
library("data.table")
library("Metrics")
library("ggplot2")
h2o.init(nthreads=64,max_mem_size = "128g")
```

## Retrieve data

```{r Retrieve Advia}
load(paste0(patho,"Tables/Transitions/ALL_merged_for_modeling_72_10_18_.Rdata",sep=""))
rm(pa)
```

### Select features

```{r}
Features<-c("strain","sex","rbc","mcv","mch","mchc","chcm","hdw"  
,"wbc","plt","glucose","bw")
Features
```

```{r}
CVV<-10 # number of FOLDS for cross validation
ree<-1 # number of repetitions 

```

### Add chronological information 
```{r}
Add_delta_variable<-function(df,V1,id){
  ftr<-data.table(df)
  V1<-V1
  V2 <- paste("Delta", V1, sep=".")
  BB<-ftr[, (V2) := .SD-shift(.SD, type='lag'), by = ID, .SDcols=V1]
  BB<-as.data.frame(BB)
  BB[is.na(BB)]<-0
  return(BB)
}

```

## Tune DNN

```{r}
tr<-Add_delta_variable(train,setdiff(Features,c("sex","strain")),id="ID")
ts<-Add_delta_variable(validate2,setdiff(Features,c("sex","strain")),id="ID")
tr[is.na(tr)]=0#Baseline delta to 0 
ts[is.na(ts)]=0
predictors<-c(Features,colnames(tr)[grepl("Delta.",colnames(tr))])
tr$sex<-as.factor(tr$sex)
ts$sex<-as.factor(ts$sex)
```


### Determine number of inputs
- Input: One per variable and level (categorical)
```{r}
df_predictors<-tr %>% select(predictors)
hidden_n <- 0
for (i in seq_along(df_predictors)) {
    col = df_predictors[i]
    if (map_chr(col, class) == "factor") {
        factor_lvls = map(col, levels)[[1]] %>% length()
        hidden_n = hidden_n + factor_lvls + 1
    }
    if (map_chr(col, class) == "numeric") {
        hidden_n = hidden_n + 1
    }
}
cat("Inputs (basic setting):",hidden_n)
```
### Build the grid

```{r,eval=FALSE, include=TRUE}
# Set the 10Folds avoiding sample overlapping
CV=10
set.seed(365)
folds <- groupdata2::fold(tr, k = CV, id_col ="ID",
                              cat_col = c('strain','cohort','sex'))
folds$sex<-as.factor(folds$sex); ts$sex<-as.factor(ts$sex)

```

##### - Arquitectures with different depths,neurons and regular. par. l1 and l2
##### - Combinatory: basic hidden neurons (hidden_n) 27.

- hidden_nx3, hidden_nx3.
- hidden_nx3, hidden_nx9.
- hidden_nx4, hidden_nx16.
- hidden_nx3, hidden_nx9, hidden_nx18.
- hidden_nx4, hidden_nx16, hidden_nx32.
- hidden_nx2, hidden_nx2, hidden_nx2, hidden_nx2.
- hidden_nx3, hidden_nx3, hidden_nx3, hidden_nx3.
- hidden_nx4, hidden_nx4, hidden_nx4, hidden_nx4.
- l1 = 1e-6.
- l1 = 1e-5.
- l1 = 1e-4.
- l1 = 1e-3.
- l1 = 1e-2.
- l2 = 1e-6.
- l2 = 1e-5.
- l2 = 1e-4.
- l2 = 1e-3.
- l2 = 1e-2.

```{r}
#Grid
grid_age <- expand_grid(hidden = list(
                              c(hidden_n*3,hidden_n*3),
                              c(hidden_n*3,hidden_n*9), 
                              c(hidden_n*4,hidden_n*16), 
c(hidden_n*3,hidden_n*9,hidden_n*18),
c(hidden_n*4,hidden_n*16,hidden_n*32),
c(hidden_n*2,hidden_n*2,hidden_n*2,hidden_n*2),
c(hidden_n*3,hidden_n*3,hidden_n*3,hidden_n*3),
c(hidden_n*4,hidden_n*4,hidden_n*4,hidden_n*4)),
                        l1=c(1e-6,1e-5,1e-4,1e-3,1e-2),
                        l2=c(1e-6,1e-5,1e-4,1e-3,1e-2),
                        epochs=200,
                        stopping_metric = "AUTO",
                        stopping_tolerance = 1e-02,
                        stopping_rounds = 3) %>%
                        mutate(row = row_number()) %>% relocate(row)
```

```{r, include=TRUE}
#Manually cache: 
load(paste0(patho,"Tables/Output/Tuning_200_models.RDATA",sep=""))
```

## Run DNNs in paralell. Apply 10FCV

```{r,eval=FALSE,include=TRUE}
# Set the 10Folds avoiding sample overlapping
CV=10
set.seed(365)
folds <- groupdata2::fold(tr, k = CV, id_col ="ID",
                              cat_col = c('strain','cohort','sex'))
folds$sex<-as.factor(folds$sex); ts$sex<-as.factor(ts$sex)

```

```{r}
#Name models
all_mod_names <- vector()
for (i in grid_age$row) {
    mod <- paste("DNN_blood", i, sep = "_")
    all_mod_names <- c(all_mod_names, mod)
}

grid_age_named <- grid_age %>%
    mutate(mod_id = all_mod_names) %>% relocate(mod_id) %>%
    select(-row)
```


```{r, eval=FALSE,render=TRUE}
## Grid search loop
library(doParallel)
library(doMC)
library(h2o)
library(R.utils)
#h2o.shutdown(prompt=TRUE): Check available cores
registerDoMC(cores=parallelly::availableCores())
#64

cl <- makeCluster(64)
registerDoParallel(cl)

#Fork: Open one H2O instance per core and run all models on the grid 
runtime_hrs <- 24
Sys.time()
withTimeout({
    big_list <- list()
    mod_names <- list()
    foreach (i = grid_age$row) %dopar% {
      library(h2o)
      port<-54321 + 3*i
      print(paste0("http://localhost:",port))
      h2o.init(nthreads = 1, max_mem_size = "1G", port=port)
      trainh2o2 <- as.h2o(folds[,c(predictors,"age_wk",".folds")])
      x <- colnames(trainh2o2)
      x <- setdiff(setdiff(colnames(trainh2o2),y),".folds")
      y <-"age_wk"
      model_id<-paste0("DNN_blood_",i,"_N",
                       format(Sys.time(), "%s"),collapse = "_")
      model_folder<-paste0(patho,"Models/Models_tunning",collapse = "_")
      #Pull model parameters from grid 
        row <- grid_age[i, ]
        mod <- paste("DNN_blood", i, sep = "_")
        mod_names <- c(mod_names, mod)
      #Run DNN using the 10FCV indexes from groupdata2 partition
        output <- h2o.deeplearning(y = y,
                                   x = setdiff(x,c(y,",folds")),
                                   model_id = model_id,
                                   training_frame =  trainh2o2,
                                   fold_column = ".folds", #indexes from split
                                   epochs = row$epochs,
                                   activation = "RectifierWithDropout",
                                   hidden = c(as.vector(row$hidden)[[1]]),
                                   l1 = row$l1,
                                   l2 = row$l2,
                                   stopping_metric = "AUTO",
                                   stopping_tolerance = row$stop_tolerance,
                                   stopping_rounds = row$stop_rounds)
        assign(mod, output)
      #Save the model to drive  
        if(!file.exists(model_folder)){dir.create(model_folder)}
        mojo_destination <- h2o.save_mojo(output, path = model_folder)
      #Save model to list of models  
        big_list <- c(big_list, eval(rlang::sym(mod)))
        names(big_list) <- mod_names
        print(i)
    }
}, timeout = (runtime_hrs*3600), onTimeout = "warning")
```


```{r, eval=TRUE}
## Grid scores to table and list
grid_scores <- tibble(mod_id = names(big_list),
                      r2_10CV = map_dbl(big_list,
                                        function(x) h2o.r2(x, xval = TRUE)),
                      mae_10CV = map_dbl(big_list,
                                        function(x) h2o.mae(x, xval = TRUE)),
                      rmse_10CV = map_dbl(big_list,
                                        function(x) h2o.rmse(x, xval = TRUE)))
```


```{r, eval=TRUE}
#Merge grid and scores
grid_results <- grid_scores %>%
    left_join(., grid_age_named, by = "mod_id")
rm(list=ls(pattern="^DNN_blood_"), i, mod)
```



## Results
Total models including 10FCV: 2200
```{r}
grid_results<-grid_results %>% arrange(-r2_10CV) %>% 
          mutate(`hidden_layers (neurons)`=as.character(hidden)) %>% 
            mutate(r_10CV=round(sqrt(r2_10CV),digits = 3)) %>%
                relocate(c(`hidden_layers (neurons)`,r_10CV), .after=mod_id) %>% 
                 select(1:3,5,8,9)
```


Once selected the model (Model 62) extract predictions

```{r, eval=FALSE,render=TRUE}

Features<-c("rbc","mcv","mch","mchc","chcm","hdw"  
,"wbc","plt","glucose","bw")

DNNs<-list.files(paste0(patho,"Models/Models_tunning/",sep=""))
data<-validate2
data<-Add_delta_variable(data,Features,id="ID")
Validate <- as.h2o(data)
Tune_validate2<-as.data.frame(matrix(rep(NA,800),ncol = 4))
colnames(Tune_validate2)<-c("DNN","R_t","MAE_t","RMSE_t")
i<-1
#Loop to import all DNNs models in the folder and predict using the vald (C07 G08)
#data and store results in a data frame  
for(file in DNNs){
  pat<-paste0(patho,"Models/Models_tunning/",file,sep="")
  imported_model <- h2o.import_mojo(pat)
  Hematology_Based_Age<-h2o.predict(object = imported_model, newdata =Validate)
  Hematology_Based_Age<-as.vector(Hematology_Based_Age)
  r_validate2<-cor(Hematology_Based_Age,data$age_wk)
  MAE<-round(mae(data$age_wk,Hematology_Based_Age),digit=2)
  RMSE<-round(rmse(data$age_wk,Hematology_Based_Age),digit=2)
  Tune_validate2[i,1]<-file
  Tune_validate2[i,2]<-r_validate2
  Tune_validate2[i,3]<-MAE
  Tune_validate2[i,4]<-RMSE
  #i<-i+1
}

```


```{r, eval=FALSE,render=TRUE}
data<-vald
data<-Add_delta_variable(data,Features,id="ID")
Validate <- as.h2o(data)
Tune_vald<-as.data.frame(matrix(rep(NA,800),ncol = 4))
colnames(Tune_vald)<-c("DNN","R_v","MAE_v","RMSE_v")
i<-1
#Loop to import all DNNs models in the folder and predict using the validate2
#(pool of cohorts) data and store results in a data frame  
for(file in DNNs){
  pat<-paste0(patho,"Models/Models_tunning/",file,sep="")
  imported_model <- h2o.import_mojo(pat)
  Hematology_Based_Age<-h2o.predict(object = imported_model, newdata =Validate)
  Hematology_Based_Age<-as.vector(Hematology_Based_Age)
  r_validate<-cor(Hematology_Based_Age,data$age_wk)
  MAE<-round(mae(data$age_wk,Hematology_Based_Age),digit=2)
  RMSE<-round(rmse(data$age_wk,Hematology_Based_Age),digit=2)
  Tune_vald[i,1]<-file
  Tune_vald[i,2]<-r_validate
  Tune_vald[i,3]<-MAE
  Tune_vald[i,4]<-RMSE
  #i<-i+1
}
h2o.shutdown()
```


```{r, eval=FALSE}
save.image(file = paste0(patho,"Tables/Output/Tuning_200_models.RDATA", sep=""))
stopCluster(cl)
```


### Grid (Double validation)
#### Total models including 10FCV : 2200 (Top 10)
Check consistency across model prediction
```{r}
clean<-function(df){
df$mod_id<-unlist(lapply(strsplit(df[,1],"_N",), "[[",1)) 
df$model<-unlist(lapply(strsplit(df[,1],"_N",), "[[",2)) 
return(as.data.frame(df))
}

Tune_validate2<-clean(Tune_validate2) %>% mutate(R_t=round(R_t,digit=3))
Tune_vald<-clean(Tune_vald) %>% mutate(R_v=round(R_v,digit=3))
grid_results_all <- grid_results %>%
    left_join(., Tune_validate2, by = "mod_id") %>% 
        left_join(., Tune_vald, by = "mod_id") %>% arrange(desc(R_v))
```

```{r}
Best_DNN<-grid_results_all %>% mutate(R_10CV=round(r_10CV,digit=3)) %>%  
                                arrange(mae_10CV) %>%      
                                        relocate(R_10CV)
Best_DNN<-Best_DNN %>% select(2,12,3,6,7,5,14:16,9:11,1,5)
A<-head(Best_DNN,40)

kable(head(A)) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

```{r,eval=FALSE}
#Manually cache
save(Best_DNN,file = paste0(patho,"Tables/Output/Best_DNNs.Rdata", sep=""))

```

